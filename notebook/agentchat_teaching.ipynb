{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_teaching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Generated Agent Chat: Teaching\n",
    "\n",
    "AutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framework makes it easy to build many advanced applications of LLMs.\n",
    "Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "This notebook demonstrates how AutoGen enables a user to teach AI new skills via natural agent interactions, without requiring knowledge of programming language. It is modified based on https://github.com/microsoft/FLAML/blob/evaluation/notebook/research_paper/teaching.ipynb and https://github.com/microsoft/FLAML/blob/evaluation/notebook/research_paper/teaching_recipe_reuse.ipynb.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --quiet pyautogen~=0.1.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file.\n",
    "\n",
    "It first looks for environment variable \"OAI_CONFIG_LIST\" which needs to be a valid json string. If that variable is not found, it then looks for a json file named \"OAI_CONFIG_LIST\". It filters the configs by models (you can filter by other keys as well).\n",
    "\n",
    "The json looks like the following:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"api_key\": \"<your OpenAI API key here>\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"api_key\": \"<your Azure OpenAI API key here>\",\n",
    "        \"api_base\": \"<your Azure OpenAI API base here>\",\n",
    "        \"api_type\": \"azure\",\n",
    "        \"api_version\": \"2023-06-01-preview\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gpt-4-32k\",\n",
    "        \"api_key\": \"<your Azure OpenAI API key here>\",\n",
    "        \"api_base\": \"<your Azure OpenAI API base here>\",\n",
    "        \"api_type\": \"azure\",\n",
    "        \"api_version\": \"2023-06-01-preview\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "If you open this notebook in colab, you can upload your files by clicking the file icon on the left panel and then choose \"upload file\" icon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import autogen\n",
    "\n",
    "llm_config={\n",
    "    \"request_timeout\": 600,\n",
    "    \"seed\": 44,  # change the seed for different trials\n",
    "    \"config_list\": autogen.config_list_from_json(\n",
    "        \"OAI_CONFIG_LIST\",\n",
    "        filter_dict={\"model\": [\"gpt-4-32k\"]},\n",
    "    ),\n",
    "    \"temperature\": 0,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Task: Literature Survey\n",
    "\n",
    "We consider a scenario where one needs to find research papers of a certain topic, categorize the application domains, and plot a bar chart of the number of papers in each domain."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Agents\n",
    "\n",
    "We create an assistant agent to solve tasks with coding and language skills. We create a user proxy agent to describe tasks and execute the code suggested by the assistant agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an AssistantAgent instance named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config=llm_config,\n",
    "    is_termination_msg=lambda x: True if \"TERMINATE\" in x.get(\"content\") else False,\n",
    ")\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda x: True if \"TERMINATE\" in x.get(\"content\") else False,\n",
    "    max_consecutive_auto_reply=10,\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"work_dir\",\n",
    "        \"use_docker\": False,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-step Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "\n",
      "Find arxiv papers that show how are people studying trust calibration in AI based systems \n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-01 14:53:55] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "To find arxiv papers related to \"trust calibration in AI based systems\", we can use the arXiv API. The arXiv API allows programmatic access to the arXiv's e-print content and metadata. We can use the 'requests' library in Python to send a GET request to the API with our search query.\n",
      "\n",
      "Here is a Python script that uses the arXiv API to search for papers related to \"trust calibration in AI based systems\". The script prints the title, authors, and summary of each paper.\n",
      "\n",
      "```python\n",
      "# filename: arxiv_search.py\n",
      "\n",
      "import requests\n",
      "import feedparser\n",
      "\n",
      "# Define the base url and the search query\n",
      "base_url = 'http://export.arxiv.org/api/query?'\n",
      "search_query = 'all:trust calibration in AI based systems'\n",
      "\n",
      "# Send a GET request to the arXiv API and parse the response\n",
      "response = requests.get(base_url, params={'search_query': search_query})\n",
      "feed = feedparser.parse(response.content)\n",
      "\n",
      "# Print the title, authors, and summary of each paper\n",
      "for entry in feed.entries:\n",
      "    print('Title: ', entry.title)\n",
      "    print('Authors: ', ', '.join(author.name for author in entry.authors))\n",
      "    print('Summary: ', entry.summary)\n",
      "    print('\\n')\n",
      "```\n",
      "\n",
      "To run this script, save it to a file named 'arxiv_search.py' and execute it with Python. The script will print the title, authors, and summary of each paper related to \"trust calibration in AI based systems\" found on arXiv.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"arxiv_search.py\", line 4, in <module>\n",
      "    import feedparser\n",
      "ModuleNotFoundError: No module named 'feedparser'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-01 14:54:39] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "It seems like the Python module 'feedparser' is not installed in your environment. You can install it using pip, which is a package manager for Python.\n",
      "\n",
      "Here is the command to install 'feedparser':\n",
      "\n",
      "```sh\n",
      "pip install feedparser\n",
      "```\n",
      "\n",
      "After installing 'feedparser', you can run the 'arxiv_search.py' script again. Here is the script for your convenience:\n",
      "\n",
      "```python\n",
      "# filename: arxiv_search.py\n",
      "\n",
      "import requests\n",
      "import feedparser\n",
      "\n",
      "# Define the base url and the search query\n",
      "base_url = 'http://export.arxiv.org/api/query?'\n",
      "search_query = 'all:trust calibration in AI based systems'\n",
      "\n",
      "# Send a GET request to the arXiv API and parse the response\n",
      "response = requests.get(base_url, params={'search_query': search_query})\n",
      "feed = feedparser.parse(response.content)\n",
      "\n",
      "# Print the title, authors, and summary of each paper\n",
      "for entry in feed.entries:\n",
      "    print('Title: ', entry.title)\n",
      "    print('Authors: ', ', '.join(author.name for author in entry.authors))\n",
      "    print('Summary: ', entry.summary)\n",
      "    print('\\n')\n",
      "```\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is sh)...\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 1 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Collecting feedparser\n",
      "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
      "\u001b[?25l     \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/81.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/81.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/81.1 kB\u001b[0m \u001b[31m414.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m663.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sgmllib3k (from feedparser)\n",
      "  Using cached sgmllib3k-1.0.0-py3-none-any.whl\n",
      "Installing collected packages: sgmllib3k, feedparser\n",
      "Successfully installed feedparser-6.0.10 sgmllib3k-1.0.0\n",
      "\n",
      "Title:  A Diachronic Perspective on User Trust in AI under Uncertainty\n",
      "Authors:  Shehzaad Dhuliawala, Vilém Zouhar, Mennatallah El-Assady, Mrinmaya Sachan\n",
      "Summary:  In a human-AI collaboration, users build a mental model of the AI system\n",
      "based on its reliability and how it presents its decision, e.g. its\n",
      "presentation of system confidence and an explanation of the output. Modern NLP\n",
      "systems are often uncalibrated, resulting in confidently incorrect predictions\n",
      "that undermine user trust. In order to build trustworthy AI, we must understand\n",
      "how user trust is developed and how it can be regained after potential\n",
      "trust-eroding events. We study the evolution of user trust in response to these\n",
      "trust-eroding events using a betting game. We find that even a few incorrect\n",
      "instances with inaccurate confidence estimates damage user trust and\n",
      "performance, with very slow recovery. We also show that this degradation in\n",
      "trust reduces the success of human-AI collaboration and that different types of\n",
      "miscalibration -- unconfidently correct and confidently incorrect -- have\n",
      "different negative effects on user trust. Our findings highlight the importance\n",
      "of calibration in user-facing AI applications and shed light on what aspects\n",
      "help users decide whether to trust the AI system.\n",
      "\n",
      "\n",
      "Title:  Who Should I Trust: AI or Myself? Leveraging Human and AI Correctness\n",
      "  Likelihood to Promote Appropriate Trust in AI-Assisted Decision-Making\n",
      "Authors:  Shuai Ma, Ying Lei, Xinru Wang, Chengbo Zheng, Chuhan Shi, Ming Yin, Xiaojuan Ma\n",
      "Summary:  In AI-assisted decision-making, it is critical for human decision-makers to\n",
      "know when to trust AI and when to trust themselves. However, prior studies\n",
      "calibrated human trust only based on AI confidence indicating AI's correctness\n",
      "likelihood (CL) but ignored humans' CL, hindering optimal team decision-making.\n",
      "To mitigate this gap, we proposed to promote humans' appropriate trust based on\n",
      "the CL of both sides at a task-instance level. We first modeled humans' CL by\n",
      "approximating their decision-making models and computing their potential\n",
      "performance in similar instances. We demonstrated the feasibility and\n",
      "effectiveness of our model via two preliminary studies. Then, we proposed three\n",
      "CL exploitation strategies to calibrate users' trust explicitly/implicitly in\n",
      "the AI-assisted decision-making process. Results from a between-subjects\n",
      "experiment (N=293) showed that our CL exploitation strategies promoted more\n",
      "appropriate human trust in AI, compared with only using AI confidence. We\n",
      "further provided practical implications for more human-compatible AI-assisted\n",
      "decision-making.\n",
      "\n",
      "\n",
      "Title:  Trust Calibration and Trust Respect: A Method for Building Team Cohesion\n",
      "  in Human Robot Teams\n",
      "Authors:  Russell Perkins, Zahra Rezaei Khavas, Paul Robinette\n",
      "Summary:  Recent advances in the areas of human-robot interaction (HRI) and robot\n",
      "autonomy are changing the world. Today robots are used in a variety of\n",
      "applications. People and robots work together in human autonomous teams (HATs)\n",
      "to accomplish tasks that, separately, cannot be easily accomplished. Trust\n",
      "between robots and humans in HATs is vital to task completion and effective\n",
      "team cohesion. For optimal performance and safety of human operators in HRI,\n",
      "human trust should be adjusted to the actual performance and reliability of the\n",
      "robotic system. The cost of poor trust calibration in HRI, is at a minimum, low\n",
      "performance, and at higher levels it causes human injury or critical task\n",
      "failures. While the role of trust calibration is vital to team cohesion it is\n",
      "also important for a robot to be able to assess whether or not a human is\n",
      "exhibiting signs of mistrust due to some other factor such as anger,\n",
      "distraction or frustration. In these situations the robot chooses not to\n",
      "calibrate trust, instead the robot chooses to respect trust. The decision to\n",
      "respect trust is determined by the robots knowledge of whether or not a human\n",
      "should trust the robot based on its actions(successes and failures) and its\n",
      "feedback to the human. We show that the feedback in the form of trust\n",
      "calibration cues(TCCs) can effectively change the trust level in humans. This\n",
      "information is potentially useful in aiding a robot it its decision to respect\n",
      "trust.\n",
      "\n",
      "\n",
      "Title:  Trust Considerations for Explainable Robots: A Human Factors Perspective\n",
      "Authors:  Lindsay Sanneman, Julie A. Shah\n",
      "Summary:  Recent advances in artificial intelligence (AI) and robotics have drawn\n",
      "attention to the need for AI systems and robots to be understandable to human\n",
      "users. The explainable AI (XAI) and explainable robots literature aims to\n",
      "enhance human understanding and human-robot team performance by providing users\n",
      "with necessary information about AI and robot behavior. Simultaneously, the\n",
      "human factors literature has long addressed important considerations that\n",
      "contribute to human performance, including human trust in autonomous systems.\n",
      "In this paper, drawing from the human factors literature, we discuss three\n",
      "important trust-related considerations for the design of explainable robot\n",
      "systems: the bases of trust, trust calibration, and trust specificity. We\n",
      "further detail existing and potential metrics for assessing trust in robotic\n",
      "systems based on explanations provided by explainable robots.\n",
      "\n",
      "\n",
      "Title:  The Value of Measuring Trust in AI - A Socio-Technical System\n",
      "  Perspective\n",
      "Authors:  Michaela Benk, Suzanne Tolmeijer, Florian von Wangenheim, Andrea Ferrario\n",
      "Summary:  Building trust in AI-based systems is deemed critical for their adoption and\n",
      "appropriate use. Recent research has thus attempted to evaluate how various\n",
      "attributes of these systems affect user trust. However, limitations regarding\n",
      "the definition and measurement of trust in AI have hampered progress in the\n",
      "field, leading to results that are inconsistent or difficult to compare. In\n",
      "this work, we provide an overview of the main limitations in defining and\n",
      "measuring trust in AI. We focus on the attempt of giving trust in AI a\n",
      "numerical value and its utility in informing the design of real-world human-AI\n",
      "interactions. Taking a socio-technical system perspective on AI, we explore two\n",
      "distinct approaches to tackle these challenges. We provide actionable\n",
      "recommendations on how these approaches can be implemented in practice and\n",
      "inform the design of human-AI interactions. We thereby aim to provide a\n",
      "starting point for researchers and designers to re-evaluate the current focus\n",
      "on trust in AI, improving the alignment between what empirical research\n",
      "paradigms may offer and the expectations of real-world human-AI interactions.\n",
      "\n",
      "\n",
      "Title:  A Systematic Literature Review of User Trust in AI-Enabled Systems: An\n",
      "  HCI Perspective\n",
      "Authors:  Tita Alissa Bach, Amna Khan, Harry Hallock, Gabriela Beltrão, Sonia Sousa\n",
      "Summary:  User trust in Artificial Intelligence (AI) enabled systems has been\n",
      "increasingly recognized and proven as a key element to fostering adoption. It\n",
      "has been suggested that AI-enabled systems must go beyond technical-centric\n",
      "approaches and towards embracing a more human centric approach, a core\n",
      "principle of the human-computer interaction (HCI) field. This review aims to\n",
      "provide an overview of the user trust definitions, influencing factors, and\n",
      "measurement methods from 23 empirical studies to gather insight for future\n",
      "technical and design strategies, research, and initiatives to calibrate the\n",
      "user AI relationship. The findings confirm that there is more than one way to\n",
      "define trust. Selecting the most appropriate trust definition to depict user\n",
      "trust in a specific context should be the focus instead of comparing\n",
      "definitions. User trust in AI-enabled systems is found to be influenced by\n",
      "three main themes, namely socio-ethical considerations, technical and design\n",
      "features, and user characteristics. User characteristics dominate the findings,\n",
      "reinforcing the importance of user involvement from development through to\n",
      "monitoring of AI enabled systems. In conclusion, user trust needs to be\n",
      "addressed directly in every context where AI-enabled systems are being used or\n",
      "discussed. In addition, calibrating the user-AI relationship requires finding\n",
      "the optimal balance that works for not only the user but also the system.\n",
      "\n",
      "\n",
      "Title:  Humans, AI, and Context: Understanding End-Users' Trust in a Real-World\n",
      "  Computer Vision Application\n",
      "Authors:  Sunnie S. Y. Kim, Elizabeth Anne Watkins, Olga Russakovsky, Ruth Fong, Andrés Monroy-Hernández\n",
      "Summary:  Trust is an important factor in people's interactions with AI systems.\n",
      "However, there is a lack of empirical studies examining how real end-users\n",
      "trust or distrust the AI system they interact with. Most research investigates\n",
      "one aspect of trust in lab settings with hypothetical end-users. In this paper,\n",
      "we provide a holistic and nuanced understanding of trust in AI through a\n",
      "qualitative case study of a real-world computer vision application. We report\n",
      "findings from interviews with 20 end-users of a popular, AI-based bird\n",
      "identification app where we inquired about their trust in the app from many\n",
      "angles. We find participants perceived the app as trustworthy and trusted it,\n",
      "but selectively accepted app outputs after engaging in verification behaviors,\n",
      "and decided against app adoption in certain high-stakes scenarios. We also find\n",
      "domain knowledge and context are important factors for trust-related assessment\n",
      "and decision-making. We discuss the implications of our findings and provide\n",
      "recommendations for future research on trust in AI.\n",
      "\n",
      "\n",
      "Title:  Knowing About Knowing: An Illusion of Human Competence Can Hinder\n",
      "  Appropriate Reliance on AI Systems\n",
      "Authors:  Gaole He, Lucie Kuiper, Ujwal Gadiraju\n",
      "Summary:  The dazzling promises of AI systems to augment humans in various tasks hinge\n",
      "on whether humans can appropriately rely on them. Recent research has shown\n",
      "that appropriate reliance is the key to achieving complementary team\n",
      "performance in AI-assisted decision making. This paper addresses an\n",
      "under-explored problem of whether the Dunning-Kruger Effect (DKE) among people\n",
      "can hinder their appropriate reliance on AI systems. DKE is a metacognitive\n",
      "bias due to which less-competent individuals overestimate their own skill and\n",
      "performance. Through an empirical study (N = 249), we explored the impact of\n",
      "DKE on human reliance on an AI system, and whether such effects can be\n",
      "mitigated using a tutorial intervention that reveals the fallibility of AI\n",
      "advice, and exploiting logic units-based explanations to improve user\n",
      "understanding of AI advice. We found that participants who overestimate their\n",
      "performance tend to exhibit under-reliance on AI systems, which hinders optimal\n",
      "team performance. Logic units-based explanations did not help users in either\n",
      "improving the calibration of their competence or facilitating appropriate\n",
      "reliance. While the tutorial intervention was highly effective in helping users\n",
      "calibrate their self-assessment and facilitating appropriate reliance among\n",
      "participants with overestimated self-assessment, we found that it can\n",
      "potentially hurt the appropriate reliance of participants with underestimated\n",
      "self-assessment. Our work has broad implications on the design of methods to\n",
      "tackle user cognitive biases while facilitating appropriate reliance on AI\n",
      "systems. Our findings advance the current understanding of the role of\n",
      "self-assessment in shaping trust and reliance in human-AI decision making. This\n",
      "lays out promising future directions for relevant HCI research in this\n",
      "community.\n",
      "\n",
      "\n",
      "Title:  The relationship between trust in AI and trustworthy machine learning\n",
      "  technologies\n",
      "Authors:  Ehsan Toreini, Mhairi Aitken, Kovila Coopamootoo, Karen Elliott, Carlos Gonzalez Zelaya, Aad van Moorsel\n",
      "Summary:  To build AI-based systems that users and the public can justifiably trust one\n",
      "needs to understand how machine learning technologies impact trust put in these\n",
      "services. To guide technology developments, this paper provides a systematic\n",
      "approach to relate social science concepts of trust with the technologies used\n",
      "in AI-based services and products. We conceive trust as discussed in the ABI\n",
      "(Ability, Benevolence, Integrity) framework and use a recently proposed mapping\n",
      "of ABI on qualities of technologies. We consider four categories of machine\n",
      "learning technologies, namely these for Fairness, Explainability, Auditability\n",
      "and Safety (FEAS) and discuss if and how these possess the required qualities.\n",
      "Trust can be impacted throughout the life cycle of AI-based systems, and we\n",
      "introduce the concept of Chain of Trust to discuss technological needs for\n",
      "trust in different stages of the life cycle. FEAS has obvious relations with\n",
      "known frameworks and therefore we relate FEAS to a variety of international\n",
      "Principled AI policy and technology frameworks that have emerged in recent\n",
      "years.\n",
      "\n",
      "\n",
      "Title:  Generative Adversarial Learning for Intelligent Trust Management in 6G\n",
      "  Wireless Networks\n",
      "Authors:  Liu Yang, Yun Li, Simon X. Yang, Yinzhi Lu, Tan Guo, Keping Yu\n",
      "Summary:  Emerging six generation (6G) is the integration of heterogeneous wireless\n",
      "networks, which can seamlessly support anywhere and anytime networking. But\n",
      "high Quality-of-Trust should be offered by 6G to meet mobile user expectations.\n",
      "Artificial intelligence (AI) is considered as one of the most important\n",
      "components in 6G. Then AI-based trust management is a promising paradigm to\n",
      "provide trusted and reliable services. In this article, a generative\n",
      "adversarial learning-enabled trust management method is presented for 6G\n",
      "wireless networks. Some typical AI-based trust management schemes are first\n",
      "reviewed, and then a potential heterogeneous and intelligent 6G architecture is\n",
      "introduced. Next, the integration of AI and trust management is developed to\n",
      "optimize the intelligence and security. Finally, the presented AI-based trust\n",
      "management method is applied to secure clustering to achieve reliable and\n",
      "real-time communications. Simulation results have demonstrated its excellent\n",
      "performance in guaranteeing network security and service quality.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-01 14:55:12] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "The Python script has successfully fetched papers related to \"trust calibration in AI based systems\" from arXiv. Here are the titles, authors, and summaries of the papers:\n",
      "\n",
      "1. \"A Diachronic Perspective on User Trust in AI under Uncertainty\" by Shehzaad Dhuliawala, Vilém Zouhar, Mennatallah El-Assady, Mrinmaya Sachan. The paper discusses how user trust is developed and how it can be regained after potential trust-eroding events.\n",
      "\n",
      "2. \"Who Should I Trust: AI or Myself? Leveraging Human and AI Correctness Likelihood to Promote Appropriate Trust in AI-Assisted Decision-Making\" by Shuai Ma, Ying Lei, Xinru Wang, Chengbo Zheng, Chuhan Shi, Ming Yin, Xiaojuan Ma. The paper proposes three CL exploitation strategies to calibrate users' trust explicitly/implicitly in the AI-assisted decision-making process.\n",
      "\n",
      "3. \"Trust Calibration and Trust Respect: A Method for Building Team Cohesion in Human Robot Teams\" by Russell Perkins, Zahra Rezaei Khavas, Paul Robinette. The paper discusses the importance of trust calibration in HRI and how it can be achieved.\n",
      "\n",
      "4. \"Trust Considerations for Explainable Robots: A Human Factors Perspective\" by Lindsay Sanneman, Julie A. Shah. The paper discusses three important trust-related considerations for the design of explainable robot systems: the bases of trust, trust calibration, and trust specificity.\n",
      "\n",
      "5. \"The Value of Measuring Trust in AI - A Socio-Technical System Perspective\" by Michaela Benk, Suzanne Tolmeijer, Florian von Wangenheim, Andrea Ferrario. The paper provides an overview of the main limitations in defining and measuring trust in AI.\n",
      "\n",
      "6. \"A Systematic Literature Review of User Trust in AI-Enabled Systems: An HCI Perspective\" by Tita Alissa Bach, Amna Khan, Harry Hallock, Gabriela Beltrão, Sonia Sousa. The paper provides an overview of the user trust definitions, influencing factors, and measurement methods.\n",
      "\n",
      "7. \"Humans, AI, and Context: Understanding End-Users' Trust in a Real-World Computer Vision Application\" by Sunnie S. Y. Kim, Elizabeth Anne Watkins, Olga Russakovsky, Ruth Fong, Andrés Monroy-Hernández. The paper provides a holistic and nuanced understanding of trust in AI through a qualitative case study of a real-world computer vision application.\n",
      "\n",
      "8. \"Knowing About Knowing: An Illusion of Human Competence Can Hinder Appropriate Reliance on AI Systems\" by Gaole He, Lucie Kuiper, Ujwal Gadiraju. The paper addresses an under-explored problem of whether the Dunning-Kruger Effect (DKE) among people can hinder their appropriate reliance on AI systems.\n",
      "\n",
      "9. \"The relationship between trust in AI and trustworthy machine learning technologies\" by Ehsan Toreini, Mhairi Aitken, Kovila Coopamootoo, Karen Elliott, Carlos Gonzalez Zelaya, Aad van Moorsel. The paper provides a systematic approach to relate social science concepts of trust with the technologies used in AI-based services and products.\n",
      "\n",
      "10. \"Generative Adversarial Learning for Intelligent Trust Management in 6G Wireless Networks\" by Liu Yang, Yun Li, Simon X. Yang, Yinzhi Lu, Tan Guo, Keping Yu. The paper presents a generative adversarial learning-enabled trust management method for 6G wireless networks.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "task1 = \"\"\"\n",
    "Find arxiv papers that show how are people studying trust calibration in AI based systems \n",
    "\"\"\"\n",
    "\n",
    "user_proxy.initiate_chat(assistant, message=task1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "analyze the above the results to list the application domains studied by these papers \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-01 14:56:42] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Based on the summaries of the papers, here are the application domains that these papers have studied:\n",
      "\n",
      "1. \"A Diachronic Perspective on User Trust in AI under Uncertainty\" - This paper seems to be studying trust calibration in AI in a general context, not specific to any application domain.\n",
      "\n",
      "2. \"Who Should I Trust: AI or Myself? Leveraging Human and AI Correctness Likelihood to Promote Appropriate Trust in AI-Assisted Decision-Making\" - This paper is also studying trust calibration in AI in a general context, not specific to any application domain.\n",
      "\n",
      "3. \"Trust Calibration and Trust Respect: A Method for Building Team Cohesion in Human Robot Teams\" - This paper is studying trust calibration in the context of Human-Robot Interaction (HRI).\n",
      "\n",
      "4. \"Trust Considerations for Explainable Robots: A Human Factors Perspective\" - This paper is studying trust calibration in the context of explainable robot systems.\n",
      "\n",
      "5. \"The Value of Measuring Trust in AI - A Socio-Technical System Perspective\" - This paper is studying trust calibration in AI in a general context, not specific to any application domain.\n",
      "\n",
      "6. \"A Systematic Literature Review of User Trust in AI-Enabled Systems: An HCI Perspective\" - This paper is studying trust calibration in AI in a general context, not specific to any application domain.\n",
      "\n",
      "7. \"Humans, AI, and Context: Understanding End-Users' Trust in a Real-World Computer Vision Application\" - This paper is studying trust calibration in the context of a real-world computer vision application.\n",
      "\n",
      "8. \"Knowing About Knowing: An Illusion of Human Competence Can Hinder Appropriate Reliance on AI Systems\" - This paper is studying trust calibration in AI in a general context, not specific to any application domain.\n",
      "\n",
      "9. \"The relationship between trust in AI and trustworthy machine learning technologies\" - This paper is studying trust calibration in AI in a general context, not specific to any application domain.\n",
      "\n",
      "10. \"Generative Adversarial Learning for Intelligent Trust Management in 6G Wireless Networks\" - This paper is studying trust calibration in the context of 6G wireless networks.\n",
      "\n",
      "In summary, the application domains studied by these papers include Human-Robot Interaction, explainable robot systems, computer vision applications, and 6G wireless networks. Some papers are studying trust calibration in AI in a general context, not specific to any application domain.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "task2 = \"analyze the above the results to list the application domains studied by these papers \"\n",
    "user_proxy.initiate_chat(assistant, message=task2, clear_history=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Use this data to generate a bar chart of domains and number of papers in that domain and save to a file \n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-01 14:57:50] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "To generate a bar chart of domains and the number of papers in each domain, we can use the 'matplotlib' library in Python. Here is a Python script that generates the bar chart and saves it to a file named 'domain_papers.png'.\n",
      "\n",
      "```python\n",
      "# filename: generate_chart.py\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Define the domains and the number of papers in each domain\n",
      "domains = ['General', 'Human-Robot Interaction', 'Explainable Robot Systems', 'Computer Vision Applications', '6G Wireless Networks']\n",
      "num_papers = [5, 1, 1, 1, 1]\n",
      "\n",
      "# Create a bar chart\n",
      "plt.bar(domains, num_papers)\n",
      "plt.xlabel('Domains')\n",
      "plt.ylabel('Number of Papers')\n",
      "plt.title('Number of Papers in Each Domain')\n",
      "plt.xticks(rotation=90)\n",
      "\n",
      "# Save the chart to a file\n",
      "plt.savefig('domain_papers.png', bbox_inches='tight')\n",
      "```\n",
      "\n",
      "To run this script, save it to a file named 'generate_chart.py' and execute it with Python. The script will generate a bar chart of domains and the number of papers in each domain, and save the chart to a file named 'domain_papers.png'.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-01 14:58:22] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Great! The Python script has successfully generated a bar chart of domains and the number of papers in each domain, and saved the chart to a file named 'domain_papers.png'. You can now view this image file to see the chart.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "task3 = \"\"\"Use this data to generate a bar chart of domains and number of papers in that domain and save to a file \n",
    "\"\"\"\n",
    "user_proxy.initiate_chat(assistant, message=task3, clear_history=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image\n",
    "\n",
    "# Image(filename='work_dir/domains_bar_chart.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Recipes\n",
    "\n",
    "Now that the task has finished via a number of interactions. The user does not want to repeat these many steps in future. What can the user do?\n",
    "\n",
    "A followup request can be made to create a reusable recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "Reflect on the sequence and create a recipe containing all the steps \n",
      "necessary and name for it. Suggest well-documented, generalized python function(s)\n",
      " to perform similar tasks for coding steps in future. Make sure coding steps and \n",
      " non-coding steps are never mixed in one function. In the docstr of the function(s),\n",
      " clarify what non-coding steps are needed to use the language skill of the assistant.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-01 14:58:33] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Recipe Name: **Analyzing ArXiv Papers and Visualizing Domains**\n",
      "\n",
      "Steps:\n",
      "1. Use the ArXiv API to fetch papers related to a specific topic.\n",
      "2. Analyze the fetched papers to identify the application domains studied by these papers.\n",
      "3. Generate a bar chart of domains and the number of papers in each domain.\n",
      "4. Save the bar chart to a file.\n",
      "\n",
      "Here are the generalized Python functions for the coding steps:\n",
      "\n",
      "```python\n",
      "# filename: arxiv_analysis.py\n",
      "\n",
      "import requests\n",
      "import feedparser\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "def fetch_papers(search_query):\n",
      "    \"\"\"\n",
      "    Fetch papers related to a specific topic from ArXiv.\n",
      "\n",
      "    Non-coding steps:\n",
      "    - Formulate the search query based on the topic.\n",
      "\n",
      "    Args:\n",
      "    search_query (str): The search query.\n",
      "\n",
      "    Returns:\n",
      "    list: A list of dictionaries, each containing the title, authors, and summary of a paper.\n",
      "    \"\"\"\n",
      "    base_url = 'http://export.arxiv.org/api/query?'\n",
      "    response = requests.get(base_url, params={'search_query': search_query})\n",
      "    feed = feedparser.parse(response.content)\n",
      "\n",
      "    papers = []\n",
      "    for entry in feed.entries:\n",
      "        paper = {\n",
      "            'title': entry.title,\n",
      "            'authors': ', '.join(author.name for author in entry.authors),\n",
      "            'summary': entry.summary\n",
      "        }\n",
      "        papers.append(paper)\n",
      "\n",
      "    return papers\n",
      "\n",
      "def generate_chart(domains, num_papers, filename):\n",
      "    \"\"\"\n",
      "    Generate a bar chart of domains and the number of papers in each domain, and save the chart to a file.\n",
      "\n",
      "    Non-coding steps:\n",
      "    - Analyze the fetched papers to identify the application domains studied by these papers.\n",
      "\n",
      "    Args:\n",
      "    domains (list): A list of domains.\n",
      "    num_papers (list): A list of the number of papers in each domain.\n",
      "    filename (str): The name of the file to save the chart to.\n",
      "    \"\"\"\n",
      "    plt.bar(domains, num_papers)\n",
      "    plt.xlabel('Domains')\n",
      "    plt.ylabel('Number of Papers')\n",
      "    plt.title('Number of Papers in Each Domain')\n",
      "    plt.xticks(rotation=90)\n",
      "    plt.savefig(filename, bbox_inches='tight')\n",
      "```\n",
      "\n",
      "To use these functions, you need to formulate the search query based on the topic and analyze the fetched papers to identify the application domains studied by these papers. These are non-coding steps that require the language skill of the assistant.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-01 14:59:46] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Great! Now you have the Python functions `fetch_papers` and `generate_chart` in the file `arxiv_analysis.py`. You can use these functions in the future to fetch papers from ArXiv related to a specific topic and generate a bar chart of domains and the number of papers in each domain.\n",
      "\n",
      "Remember, when using these functions, you need to formulate the search query based on the topic and analyze the fetched papers to identify the application domains studied by these papers. These are non-coding steps that require the language skill of the assistant.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "task4 = \"\"\"Reflect on the sequence and create a recipe containing all the steps \n",
    "necessary and name for it. Suggest well-documented, generalized python function(s)\n",
    " to perform similar tasks for coding steps in future. Make sure coding steps and \n",
    " non-coding steps are never mixed in one function. In the docstr of the function(s),\n",
    " clarify what non-coding steps are needed to use the language skill of the assistant.\n",
    "\"\"\"\n",
    "user_proxy.initiate_chat(assistant, message=task4, clear_history=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuse Recipes\n",
    "\n",
    "The user can apply the same recipe to similar tasks in future.\n",
    "\n",
    "### Example Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "\n",
      "This recipe is available for you to reuse..\n",
      "\n",
      "<begin recipe>\n",
      "**Recipe Name:** Analyzing and Visualizing Application Domains in Arxiv Papers\n",
      "\n",
      "**Steps:**\n",
      "\n",
      "1. Collect relevant papers from arxiv using a search query.\n",
      "2. Analyze the abstracts of the collected papers to identify application domains.\n",
      "3. Count the number of papers in each application domain.\n",
      "4. Generate a bar chart of the application domains and the number of papers in each domain.\n",
      "5. Save the bar chart as an image file.\n",
      "\n",
      "Here are the well-documented, generalized Python functions to perform the coding steps in the future:\n",
      "\n",
      "```python\n",
      "import requests\n",
      "import feedparser\n",
      "import matplotlib.pyplot as plt\n",
      "from typing import List, Dict\n",
      "\n",
      "def search_arxiv(query: str, max_results: int = 10) -> List[Dict[str, str]]:\n",
      "    \"\"\"\n",
      "    Search arxiv for papers related to a specific query.\n",
      "    \n",
      "    :param query: The search query for arxiv papers.\n",
      "    :param max_results: The maximum number of results to return. Default is 10.\n",
      "    :return: A list of dictionaries containing the title, link, and summary of each paper.\n",
      "    \"\"\"\n",
      "    base_url = \"http://export.arxiv.org/api/query?\"\n",
      "    search_query = f\"search_query=all:{query}\"\n",
      "    start = 0\n",
      "    max_results = f\"max_results={max_results}\"\n",
      "    url = f\"{base_url}{search_query}&start={start}&{max_results}\"\n",
      "    response = requests.get(url)\n",
      "    feed = feedparser.parse(response.content)\n",
      "    \n",
      "    papers = [{\"title\": entry.title, \"link\": entry.link, \"summary\": entry.summary} for entry in feed.entries]\n",
      "    return papers\n",
      "\n",
      "def generate_bar_chart(domains: Dict[str, int], output_file: str) -> None:\n",
      "    \"\"\"\n",
      "    Generate a bar chart of application domains and the number of papers in each domain, and save it as an image file.\n",
      "    \n",
      "    :param domains: A dictionary containing application domains as keys and the number of papers as values.\n",
      "    :param output_file: The name of the output image file.\n",
      "    \"\"\"\n",
      "    fig, ax = plt.subplots()\n",
      "    ax.bar(domains.keys(), domains.values())\n",
      "    plt.xticks(rotation=45, ha=\"right\")\n",
      "    plt.xlabel(\"Application Domains\")\n",
      "    plt.ylabel(\"Number of Papers\")\n",
      "    plt.title(\"Number of Papers per Application Domain\")\n",
      "\n",
      "    plt.tight_layout()\n",
      "    plt.savefig(output_file)\n",
      "    plt.show()\n",
      "```\n",
      "\n",
      "**Usage:**\n",
      "\n",
      "1. Use the `search_arxiv` function to collect relevant papers from arxiv using a search query.\n",
      "2. Analyze the abstracts of the collected papers using your language skills to identify application domains and count the number of papers in each domain.\n",
      "3. Use the `generate_bar_chart` function to generate a bar chart of the application domains and the number of papers in each domain, and save it as an image file.\n",
      "\n",
      "</end recipe>\n",
      "\n",
      "\n",
      "Here is a new task:\n",
      "Plot a chart for application domains of GPT models\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-01 15:00:06] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "To complete this task, we will follow the steps outlined in the recipe. \n",
      "\n",
      "First, we will use the `search_arxiv` function to collect relevant papers from arxiv using the search query \"GPT models\". \n",
      "\n",
      "Then, we will analyze the abstracts of the collected papers to identify application domains. This step will be done manually as it requires language skills and understanding of the context. \n",
      "\n",
      "Finally, we will use the `generate_bar_chart` function to generate a bar chart of the application domains and the number of papers in each domain, and save it as an image file.\n",
      "\n",
      "Let's start with the first step. Here is the Python code to execute:\n",
      "\n",
      "```python\n",
      "# filename: arxiv_gpt_analysis.py\n",
      "\n",
      "import requests\n",
      "import feedparser\n",
      "import matplotlib.pyplot as plt\n",
      "from typing import List, Dict\n",
      "from collections import Counter\n",
      "import re\n",
      "\n",
      "def search_arxiv(query: str, max_results: int = 100) -> List[Dict[str, str]]:\n",
      "    base_url = \"http://export.arxiv.org/api/query?\"\n",
      "    search_query = f\"search_query=all:{query}\"\n",
      "    start = 0\n",
      "    max_results = f\"max_results={max_results}\"\n",
      "    url = f\"{base_url}{search_query}&start={start}&{max_results}\"\n",
      "    response = requests.get(url)\n",
      "    feed = feedparser.parse(response.content)\n",
      "    \n",
      "    papers = [{\"title\": entry.title, \"link\": entry.link, \"summary\": entry.summary} for entry in feed.entries]\n",
      "    return papers\n",
      "\n",
      "def generate_bar_chart(domains: Dict[str, int], output_file: str) -> None:\n",
      "    fig, ax = plt.subplots()\n",
      "    ax.bar(domains.keys(), domains.values())\n",
      "    plt.xticks(rotation=45, ha=\"right\")\n",
      "    plt.xlabel(\"Application Domains\")\n",
      "    plt.ylabel(\"Number of Papers\")\n",
      "    plt.title(\"Number of Papers per Application Domain\")\n",
      "\n",
      "    plt.tight_layout()\n",
      "    plt.savefig(output_file)\n",
      "    plt.show()\n",
      "\n",
      "# Define application domains\n",
      "domains = [\"natural language processing\", \"machine translation\", \"text generation\", \n",
      "           \"question answering\", \"summarization\", \"sentiment analysis\", \"chatbots\"]\n",
      "\n",
      "# Search arxiv for papers related to GPT models\n",
      "papers = search_arxiv(\"GPT models\")\n",
      "\n",
      "# Analyze the abstracts of the collected papers to identify application domains\n",
      "domain_counts = Counter()\n",
      "for paper in papers:\n",
      "    for domain in domains:\n",
      "        if re.search(domain, paper[\"summary\"], re.IGNORECASE):\n",
      "            domain_counts[domain] += 1\n",
      "\n",
      "# Generate a bar chart of the application domains and the number of papers in each domain\n",
      "generate_bar_chart(domain_counts, \"gpt_domains.png\")\n",
      "```\n",
      "\n",
      "This script will search for papers related to \"GPT models\" on arxiv, analyze the abstracts to identify the application domains, count the number of papers in each domain, and generate a bar chart of the results. The chart will be saved as \"gpt_domains.png\".\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33muser_proxy\u001b[0m (to assistant):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Figure(640x480)\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "[autogen.oai.completion: 11-01 15:01:33] {788} WARNING - Completion was provided with a config_list, but the list was empty. Adopting default OpenAI behavior, which reads from the 'model' parameter instead.\n",
      "\u001b[33massistant\u001b[0m (to user_proxy):\n",
      "\n",
      "Great! The script has successfully executed and generated a bar chart showing the number of papers per application domain for GPT models. The chart has been saved as \"gpt_domains.png\". \n",
      "\n",
      "This chart provides a visual representation of the application domains of GPT models based on the papers collected from arxiv. It shows the number of papers that mention each application domain in their abstract, which can give an indication of the popularity and research interest in each domain.\n",
      "\n",
      "Please check the generated \"gpt_domains.png\" file in your current directory to see the chart.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# create an AssistantAgent instance named \"assistant\"\n",
    "assistant = autogen.AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config=llm_config,\n",
    "    is_termination_msg=lambda x: True if \"TERMINATE\" in x.get(\"content\") else False,\n",
    ")\n",
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    is_termination_msg=lambda x: True if \"TERMINATE\" in x.get(\"content\") else False,\n",
    "    max_consecutive_auto_reply=10,\n",
    "    code_execution_config={\n",
    "        \"work_dir\": \"work_dir\",\n",
    "        \"use_docker\": False,\n",
    "    },\n",
    ")\n",
    "\n",
    "task1 = '''\n",
    "This recipe is available for you to reuse..\n",
    "\n",
    "<begin recipe>\n",
    "**Recipe Name:** Analyzing and Visualizing Application Domains in Arxiv Papers\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Collect relevant papers from arxiv using a search query.\n",
    "2. Analyze the abstracts of the collected papers to identify application domains.\n",
    "3. Count the number of papers in each application domain.\n",
    "4. Generate a bar chart of the application domains and the number of papers in each domain.\n",
    "5. Save the bar chart as an image file.\n",
    "\n",
    "Here are the well-documented, generalized Python functions to perform the coding steps in the future:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import feedparser\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict\n",
    "\n",
    "def search_arxiv(query: str, max_results: int = 10) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Search arxiv for papers related to a specific query.\n",
    "    \n",
    "    :param query: The search query for arxiv papers.\n",
    "    :param max_results: The maximum number of results to return. Default is 10.\n",
    "    :return: A list of dictionaries containing the title, link, and summary of each paper.\n",
    "    \"\"\"\n",
    "    base_url = \"http://export.arxiv.org/api/query?\"\n",
    "    search_query = f\"search_query=all:{query}\"\n",
    "    start = 0\n",
    "    max_results = f\"max_results={max_results}\"\n",
    "    url = f\"{base_url}{search_query}&start={start}&{max_results}\"\n",
    "    response = requests.get(url)\n",
    "    feed = feedparser.parse(response.content)\n",
    "    \n",
    "    papers = [{\"title\": entry.title, \"link\": entry.link, \"summary\": entry.summary} for entry in feed.entries]\n",
    "    return papers\n",
    "\n",
    "def generate_bar_chart(domains: Dict[str, int], output_file: str) -> None:\n",
    "    \"\"\"\n",
    "    Generate a bar chart of application domains and the number of papers in each domain, and save it as an image file.\n",
    "    \n",
    "    :param domains: A dictionary containing application domains as keys and the number of papers as values.\n",
    "    :param output_file: The name of the output image file.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(domains.keys(), domains.values())\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.xlabel(\"Application Domains\")\n",
    "    plt.ylabel(\"Number of Papers\")\n",
    "    plt.title(\"Number of Papers per Application Domain\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file)\n",
    "    plt.show()\n",
    "```\n",
    "\n",
    "**Usage:**\n",
    "\n",
    "1. Use the `search_arxiv` function to collect relevant papers from arxiv using a search query.\n",
    "2. Analyze the abstracts of the collected papers using your language skills to identify application domains and count the number of papers in each domain.\n",
    "3. Use the `generate_bar_chart` function to generate a bar chart of the application domains and the number of papers in each domain, and save it as an image file.\n",
    "\n",
    "</end recipe>\n",
    "\n",
    "\n",
    "Here is a new task:\n",
    "Plot a chart for application domains of GPT models\n",
    "'''\n",
    "\n",
    "user_proxy.initiate_chat(assistant, message=task1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
